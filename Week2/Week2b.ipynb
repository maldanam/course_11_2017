{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 - Let's get classifying\n",
    "\n",
    "In this session, we will try to get some classifiers running. If time permits, we will do a bit more complex example as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Library and imports, as always\n",
    "We will make the essential imports. Further imports will be done later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "\n",
    "#Ignore Warnings - save some confusion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Pandas more columns\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Add input as import path\n",
    "sys.path.insert(0,'../input')\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Import the data from the dataset\n",
    "train_data = pd.read_csv('../input/train.csv',index_col='id')\n",
    "test_data = pd.read_csv('../input/test.csv',index_col='id')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Getting our input ready\n",
    "Oops, we spoke too soon. Before we can think of classifying, we got to make sure our inputs are the way we would like them\n",
    "\n",
    "### MiniStep 1 - Feature Transforms\n",
    "What we would like to be doing here is to take existing features, and simplify them. Not still thinking about inputting missing features, or to normalize/quantify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pclass  survived     sex   age  sibsp  parch        fare cabin boat  \\\n",
      "id                                                                          \n",
      "277        1         1  female   NaN      1      0  4_quartile     B    6   \n",
      "562        2         1  female  30.0      0      0  2_quartile     N   13   \n",
      "111        1         1  female  24.0      3      2  4_quartile     C   10   \n",
      "930        3         0    male   NaN      1      0  1_quartile     N  NaN   \n",
      "841        3         0  female  17.0      0      0  1_quartile     N  NaN   \n",
      "585        2         0    male  27.0      1      0  3_quartile     N  NaN   \n",
      "609        3         0    male  26.0      0      0  2_quartile     N  NaN   \n",
      "540        2         1  female   2.0      1      1  3_quartile     N   11   \n",
      "1075       3         0    male  23.0      0      0  2_quartile     N  NaN   \n",
      "390        2         0    male  17.0      0      0  4_quartile     N  NaN   \n",
      "921        3         0    male   NaN      0      0  1_quartile     N    A   \n",
      "339        2         1    male   1.0      2      1  4_quartile     F   11   \n",
      "155        1         1  female  52.0      1      1  4_quartile     B    3   \n",
      "564        2         1  female  40.0      0      0  2_quartile     N    9   \n",
      "694        3         0    male  19.0      0      0  1_quartile     N  NaN   \n",
      "1028       3         1  female   NaN      1      0  3_quartile     N   16   \n",
      "1184       3         0    male   NaN      2      0  3_quartile     N  NaN   \n",
      "633        3         0    male  20.0      0      0  1_quartile     N  NaN   \n",
      "907        3         0  female  20.0      1      0  2_quartile     N  NaN   \n",
      "426        2         0    male  30.0      0      0  2_quartile     N  NaN   \n",
      "1210       3         0    male  40.0      1      4  3_quartile     N  NaN   \n",
      "257        1         1  female  35.0      1      0  4_quartile     C   11   \n",
      "474        2         0    male  31.0      0      0  2_quartile     N  NaN   \n",
      "439        2         0    male  49.0      1      2  4_quartile     N  NaN   \n",
      "9          1         0    male  71.0      0      0  4_quartile     N  NaN   \n",
      "948        3         0    male   NaN      0      0  1_quartile     N  NaN   \n",
      "762        3         1    male   1.0      1      2  3_quartile     N   10   \n",
      "802        3         0    male   NaN      0      0  1_quartile     N  NaN   \n",
      "482        2         1  female  17.0      0      0  2_quartile     N   12   \n",
      "893        3         0    male  29.0      0      0  1_quartile     N  NaN   \n",
      "...      ...       ...     ...   ...    ...    ...         ...   ...  ...   \n",
      "408        2         0    male  18.0      0      0  2_quartile     N  NaN   \n",
      "87         1         1    male  27.0      0      0  3_quartile     N    3   \n",
      "810        3         0    male  16.0      1      3  4_quartile     N  NaN   \n",
      "276        1         0    male  57.0      1      0  4_quartile     B  NaN   \n",
      "751        3         0    male  25.0      0      0  1_quartile     N  NaN   \n",
      "550        2         1  female  24.0      2      3  3_quartile     N    4   \n",
      "231        1         1    male  52.0      0      0  3_quartile     C    6   \n",
      "879        3         0    male   NaN      0      0  1_quartile     N  NaN   \n",
      "896        3         0    male  49.0      0      0     Unknown     N  NaN   \n",
      "835        3         0    male   NaN      0      0  2_quartile     N  NaN   \n",
      "752        3         0    male  24.0      2      0  3_quartile     N  NaN   \n",
      "984        3         1  female   NaN      0      0  1_quartile     N   15   \n",
      "163        1         1  female  35.0      1      0  4_quartile     N    8   \n",
      "1063       3         0    male  41.0      0      0  1_quartile     N  NaN   \n",
      "29         1         1    male  28.0      0      0  3_quartile     C    D   \n",
      "200        1         0    male  46.0      0      0  4_quartile     C  NaN   \n",
      "285        1         0    male  67.0      1      0  4_quartile     C  NaN   \n",
      "1267       3         0  female  30.0      1      1  3_quartile     N  NaN   \n",
      "783        3         1    male  24.0      0      0  1_quartile     N    D   \n",
      "1074       3         0    male   NaN      0      0  1_quartile     N  NaN   \n",
      "1087       3         0    male  28.0      0      0  1_quartile     N  NaN   \n",
      "982        3         0    male   NaN      0      0  1_quartile     N  NaN   \n",
      "677        3         0    male  26.0      0      0  1_quartile     N  NaN   \n",
      "977        3         0    male  20.5      0      0  1_quartile     N  NaN   \n",
      "35         1         1  female  45.0      0      0  4_quartile     N    4   \n",
      "626        3         0  female  38.0      4      2  1_quartile     N  NaN   \n",
      "640        3         0    male   9.0      4      2  4_quartile     N  NaN   \n",
      "845        3         1  female  24.0      1      0  3_quartile     N   15   \n",
      "1291       3         0    male   NaN      0      0  2_quartile     N  NaN   \n",
      "639        3         0    male   5.0      4      2  4_quartile     N  NaN   \n",
      "\n",
      "       body                    lname nameprefix  \n",
      "id                                               \n",
      "277     NaN                 Spencer,       Mrs.  \n",
      "562     NaN                 Slayter,      Miss.  \n",
      "111     NaN                 Fortune,      Miss.  \n",
      "930     NaN                 Kiernan,        Mr.  \n",
      "841     NaN                Hagardon,      Miss.  \n",
      "585   293.0                   Weisz,        Mr.  \n",
      "609   103.0                   Adams,        Mr.  \n",
      "540     NaN                   Quick,      Miss.  \n",
      "1075    NaN                   Odahl,        Mr.  \n",
      "390     NaN                  Deacon,        Mr.  \n",
      "921     NaN                   Keefe,        Mr.  \n",
      "339     NaN                  Becker,    Master.  \n",
      "155     NaN                    Hays,       Mrs.  \n",
      "564     NaN                   Smith,      Miss.  \n",
      "694     NaN                   Burke,        Mr.  \n",
      "1028    NaN                   Moran,      Miss.  \n",
      "1184    NaN                  Samaan,        Mr.  \n",
      "633     NaN              Andreasson,        Mr.  \n",
      "907     NaN                 Jussila,      Miss.  \n",
      "426    75.0                    Hale,        Mr.  \n",
      "1210    NaN                   Skoog,        Mr.  \n",
      "257     NaN                Schabert,       Mrs.  \n",
      "474   165.0                Kvillner,        Mr.  \n",
      "439     NaN                  Herman,        Mr.  \n",
      "9      22.0            Artagaveytia,        Mr.  \n",
      "948     NaN                    Lane,        Mr.  \n",
      "762     NaN                    Dean,    Master.  \n",
      "802     NaN                   Flynn,        Mr.  \n",
      "482     NaN                 Lehmann,      Miss.  \n",
      "893     NaN               Johansson,        Mr.  \n",
      "...     ...                      ...        ...  \n",
      "408     NaN               Fillbrook,        Mr.  \n",
      "87      NaN                  Daniel,        Mr.  \n",
      "810     NaN                    Ford,        Mr.  \n",
      "276     NaN                 Spencer,        Mr.  \n",
      "751     NaN               Dantcheff,        Mr.  \n",
      "550     NaN                Richards,       Mrs.  \n",
      "231     NaN                 Peuchen,     Major.  \n",
      "879     NaN                 Ivanoff,        Mr.  \n",
      "896     NaN                 Johnson,        Mr.  \n",
      "835     NaN                   Guest,        Mr.  \n",
      "752     NaN                  Davies,        Mr.  \n",
      "984     NaN                 Madigan,      Miss.  \n",
      "163     NaN               Holverson,       Mrs.  \n",
      "1063    NaN                   Nirva,        Mr.  \n",
      "29      NaN  Bjornstrom-Steffansson,        Mr.  \n",
      "200   292.0                McCaffry,        Mr.  \n",
      "285    96.0                  Straus,        Mr.  \n",
      "1267    NaN                      Van      Impe,  \n",
      "783     NaN                Duquemin,        Mr.  \n",
      "1074    NaN                O'Connor,        Mr.  \n",
      "1087    NaN                  Olsson,        Mr.  \n",
      "982     NaN               Lyntakoff,        Mr.  \n",
      "677     NaN             Bostandyeff,        Mr.  \n",
      "977     NaN                  Lovell,        Mr.  \n",
      "35      NaN                   Bowen,      Miss.  \n",
      "626     NaN               Andersson,      Miss.  \n",
      "640     NaN                 Asplund,    Master.  \n",
      "845     NaN             Hakkarainen,       Mrs.  \n",
      "1291    NaN                  Willer,        Mr.  \n",
      "639     NaN                 Asplund,    Master.  \n",
      "\n",
      "[654 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "def simplify_fares(df):\n",
    "    df.fare = df.fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.fare, bins, labels=group_names)\n",
    "    df.fare = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.cabin = df.cabin.fillna('N')\n",
    "    df.cabin = df.cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_name(df):\n",
    "    df['lname'] = df.name.apply(lambda x: x.split(' ')[0])\n",
    "    df['lname'].fillna(' ')\n",
    "    df['nameprefix'] = df.name.apply(lambda x: x.split(' ')[1])\n",
    "    df['nameprefix'].fillna(' ')\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['ticket', 'name', 'embarked', 'home.dest'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_fares(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = transform_features(train_data)\n",
    "test_data  = transform_features(test_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniStep 2 - Feature Encoding \n",
    "Our next step is to take existing features which possibly have text to convert them into numbers. \n",
    "**Categorical->Numerical**\n",
    "In our previous sessions, we saw how to do it manually. \n",
    "Here, we will use the awesome scikit-learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare\n",
      "cabin\n",
      "sex\n",
      "lname\n",
      "nameprefix\n",
      "boat\n",
      "      pclass  survived  sex   age  sibsp  parch  fare  cabin  boat   body  \\\n",
      "id                                                                          \n",
      "277        1         1    0   NaN      1      0     3      1    17    NaN   \n",
      "562        2         1    0  30.0      0      0     1      7     4    NaN   \n",
      "111        1         1    0  24.0      3      2     3      2     1    NaN   \n",
      "930        3         0    1   NaN      1      0     0      7    27    NaN   \n",
      "841        3         0    0  17.0      0      0     0      7    27    NaN   \n",
      "585        2         0    1  27.0      1      0     2      7    27  293.0   \n",
      "609        3         0    1  26.0      0      0     1      7    27  103.0   \n",
      "540        2         1    0   2.0      1      1     2      7     2    NaN   \n",
      "1075       3         0    1  23.0      0      0     1      7    27    NaN   \n",
      "390        2         0    1  17.0      0      0     3      7    27    NaN   \n",
      "921        3         0    1   NaN      0      0     0      7    22    NaN   \n",
      "339        2         1    1   1.0      2      1     3      5     2    NaN   \n",
      "155        1         1    0  52.0      1      1     3      1    12    NaN   \n",
      "564        2         1    0  40.0      0      0     1      7    21    NaN   \n",
      "694        3         0    1  19.0      0      0     0      7    27    NaN   \n",
      "1028       3         1    0   NaN      1      0     2      7    10    NaN   \n",
      "1184       3         0    1   NaN      2      0     2      7    27    NaN   \n",
      "633        3         0    1  20.0      0      0     0      7    27    NaN   \n",
      "907        3         0    0  20.0      1      0     1      7    27    NaN   \n",
      "426        2         0    1  30.0      0      0     1      7    27   75.0   \n",
      "1210       3         0    1  40.0      1      4     2      7    27    NaN   \n",
      "257        1         1    0  35.0      1      0     3      2     2    NaN   \n",
      "474        2         0    1  31.0      0      0     1      7    27  165.0   \n",
      "439        2         0    1  49.0      1      2     3      7    27    NaN   \n",
      "9          1         0    1  71.0      0      0     3      7    27   22.0   \n",
      "948        3         0    1   NaN      0      0     0      7    27    NaN   \n",
      "762        3         1    1   1.0      1      2     2      7     1    NaN   \n",
      "802        3         0    1   NaN      0      0     0      7    27    NaN   \n",
      "482        2         1    0  17.0      0      0     1      7     3    NaN   \n",
      "893        3         0    1  29.0      0      0     0      7    27    NaN   \n",
      "...      ...       ...  ...   ...    ...    ...   ...    ...   ...    ...   \n",
      "408        2         0    1  18.0      0      0     1      7    27    NaN   \n",
      "87         1         1    1  27.0      0      0     2      7    12    NaN   \n",
      "810        3         0    1  16.0      1      3     3      7    27    NaN   \n",
      "276        1         0    1  57.0      1      0     3      1    27    NaN   \n",
      "751        3         0    1  25.0      0      0     0      7    27    NaN   \n",
      "550        2         1    0  24.0      2      3     2      7    13    NaN   \n",
      "231        1         1    1  52.0      0      0     2      2    17    NaN   \n",
      "879        3         0    1   NaN      0      0     0      7    27    NaN   \n",
      "896        3         0    1  49.0      0      0     4      7    27    NaN   \n",
      "835        3         0    1   NaN      0      0     1      7    27    NaN   \n",
      "752        3         0    1  24.0      2      0     2      7    27    NaN   \n",
      "984        3         1    0   NaN      0      0     0      7     8    NaN   \n",
      "163        1         1    0  35.0      1      0     3      7    19    NaN   \n",
      "1063       3         0    1  41.0      0      0     0      7    27    NaN   \n",
      "29         1         1    1  28.0      0      0     2      2    26    NaN   \n",
      "200        1         0    1  46.0      0      0     3      2    27  292.0   \n",
      "285        1         0    1  67.0      1      0     3      2    27   96.0   \n",
      "1267       3         0    0  30.0      1      1     2      7    27    NaN   \n",
      "783        3         1    1  24.0      0      0     0      7    26    NaN   \n",
      "1074       3         0    1   NaN      0      0     0      7    27    NaN   \n",
      "1087       3         0    1  28.0      0      0     0      7    27    NaN   \n",
      "982        3         0    1   NaN      0      0     0      7    27    NaN   \n",
      "677        3         0    1  26.0      0      0     0      7    27    NaN   \n",
      "977        3         0    1  20.5      0      0     0      7    27    NaN   \n",
      "35         1         1    0  45.0      0      0     3      7    13    NaN   \n",
      "626        3         0    0  38.0      4      2     0      7    27    NaN   \n",
      "640        3         0    1   9.0      4      2     3      7    27    NaN   \n",
      "845        3         1    0  24.0      1      0     2      7     8    NaN   \n",
      "1291       3         0    1   NaN      0      0     1      7    27    NaN   \n",
      "639        3         0    1   5.0      4      2     3      7    27    NaN   \n",
      "\n",
      "      lname  nameprefix  \n",
      "id                       \n",
      "277     755          20  \n",
      "562     741          16  \n",
      "111     257          16  \n",
      "930     406          19  \n",
      "841     303          16  \n",
      "585     830          19  \n",
      "609       7          19  \n",
      "540     652          16  \n",
      "1075    591          19  \n",
      "390     198          19  \n",
      "921     399          19  \n",
      "339      66          13  \n",
      "155     323          20  \n",
      "564     747          16  \n",
      "694     108          19  \n",
      "1028    538          16  \n",
      "1184    706          19  \n",
      "633      22          19  \n",
      "907     388          16  \n",
      "426     306          19  \n",
      "1210    739          19  \n",
      "257     712          20  \n",
      "474     418          19  \n",
      "439     335          19  \n",
      "9        30          19  \n",
      "948     426          19  \n",
      "762     199          13  \n",
      "802     252          19  \n",
      "482     435          16  \n",
      "893     381          19  \n",
      "...     ...         ...  \n",
      "408     247          19  \n",
      "87      190          19  \n",
      "810     255          19  \n",
      "276     755          19  \n",
      "751     193          19  \n",
      "550     666          20  \n",
      "231     641          12  \n",
      "879     367          19  \n",
      "896     382          19  \n",
      "835     299          19  \n",
      "752     195          19  \n",
      "984     474          16  \n",
      "163     349          20  \n",
      "1063    573          19  \n",
      "29       83          19  \n",
      "200     499          19  \n",
      "285     772          19  \n",
      "1267    811           9  \n",
      "783     226          19  \n",
      "1074    584          19  \n",
      "1087    595          19  \n",
      "982     471          19  \n",
      "677      88          19  \n",
      "977     465          19  \n",
      "35       92          16  \n",
      "626      21          16  \n",
      "640      33          13  \n",
      "845     305          20  \n",
      "1291    845          19  \n",
      "639      33          13  \n",
      "\n",
      "[654 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['fare', 'cabin', 'sex', 'lname', 'nameprefix', 'boat']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "\n",
    "    for feature in features:\n",
    "        print feature\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "\n",
    "train_data['boat'] = train_data['boat'].astype('str')\n",
    "test_data['boat'] = test_data['boat'].astype('str')\n",
    "train_data, test_data = encode_features(train_data, test_data)\n",
    "print(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniStep 3 - Missing Data!\n",
    "\n",
    "Here, we use sklearn's imputer to directly fill in missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pclass  survived  sex        age  sibsp  parch  fare  cabin  boat  \\\n",
      "id                                                                        \n",
      "277        1         1    0  29.881135      1      0     3      1  17.0   \n",
      "562        2         1    0  30.000000      0      0     1      7   4.0   \n",
      "111        1         1    0  24.000000      3      2     3      2   1.0   \n",
      "930        3         0    1  29.881135      1      0     0      7  27.0   \n",
      "841        3         0    0  17.000000      0      0     0      7  27.0   \n",
      "585        2         0    1  27.000000      1      0     2      7  27.0   \n",
      "609        3         0    1  26.000000      0      0     1      7  27.0   \n",
      "540        2         1    0   2.000000      1      1     2      7   2.0   \n",
      "1075       3         0    1  23.000000      0      0     1      7  27.0   \n",
      "390        2         0    1  17.000000      0      0     3      7  27.0   \n",
      "921        3         0    1  29.881135      0      0     0      7  22.0   \n",
      "339        2         1    1   1.000000      2      1     3      5   2.0   \n",
      "155        1         1    0  52.000000      1      1     3      1  12.0   \n",
      "564        2         1    0  40.000000      0      0     1      7  21.0   \n",
      "694        3         0    1  19.000000      0      0     0      7  27.0   \n",
      "1028       3         1    0  29.881135      1      0     2      7  10.0   \n",
      "1184       3         0    1  29.881135      2      0     2      7  27.0   \n",
      "633        3         0    1  20.000000      0      0     0      7  27.0   \n",
      "907        3         0    0  20.000000      1      0     1      7  27.0   \n",
      "426        2         0    1  30.000000      0      0     1      7  27.0   \n",
      "1210       3         0    1  40.000000      1      4     2      7  27.0   \n",
      "257        1         1    0  35.000000      1      0     3      2   2.0   \n",
      "474        2         0    1  31.000000      0      0     1      7  27.0   \n",
      "439        2         0    1  49.000000      1      2     3      7  27.0   \n",
      "9          1         0    1  71.000000      0      0     3      7  27.0   \n",
      "948        3         0    1  29.881135      0      0     0      7  27.0   \n",
      "762        3         1    1   1.000000      1      2     2      7   1.0   \n",
      "802        3         0    1  29.881135      0      0     0      7  27.0   \n",
      "482        2         1    0  17.000000      0      0     1      7   3.0   \n",
      "893        3         0    1  29.000000      0      0     0      7  27.0   \n",
      "...      ...       ...  ...        ...    ...    ...   ...    ...   ...   \n",
      "408        2         0    1  18.000000      0      0     1      7  27.0   \n",
      "87         1         1    1  27.000000      0      0     2      7  12.0   \n",
      "810        3         0    1  16.000000      1      3     3      7  27.0   \n",
      "276        1         0    1  57.000000      1      0     3      1  27.0   \n",
      "751        3         0    1  25.000000      0      0     0      7  27.0   \n",
      "550        2         1    0  24.000000      2      3     2      7  13.0   \n",
      "231        1         1    1  52.000000      0      0     2      2  17.0   \n",
      "879        3         0    1  29.881135      0      0     0      7  27.0   \n",
      "896        3         0    1  49.000000      0      0     4      7  27.0   \n",
      "835        3         0    1  29.881135      0      0     1      7  27.0   \n",
      "752        3         0    1  24.000000      2      0     2      7  27.0   \n",
      "984        3         1    0  29.881135      0      0     0      7   8.0   \n",
      "163        1         1    0  35.000000      1      0     3      7  19.0   \n",
      "1063       3         0    1  41.000000      0      0     0      7  27.0   \n",
      "29         1         1    1  28.000000      0      0     2      2  26.0   \n",
      "200        1         0    1  46.000000      0      0     3      2  27.0   \n",
      "285        1         0    1  67.000000      1      0     3      2  27.0   \n",
      "1267       3         0    0  30.000000      1      1     2      7  27.0   \n",
      "783        3         1    1  24.000000      0      0     0      7  26.0   \n",
      "1074       3         0    1  29.881135      0      0     0      7  27.0   \n",
      "1087       3         0    1  28.000000      0      0     0      7  27.0   \n",
      "982        3         0    1  29.881135      0      0     0      7  27.0   \n",
      "677        3         0    1  26.000000      0      0     0      7  27.0   \n",
      "977        3         0    1  20.500000      0      0     0      7  27.0   \n",
      "35         1         1    0  45.000000      0      0     3      7  13.0   \n",
      "626        3         0    0  38.000000      4      2     0      7  27.0   \n",
      "640        3         0    1   9.000000      4      2     3      7  27.0   \n",
      "845        3         1    0  24.000000      1      0     2      7   8.0   \n",
      "1291       3         0    1  29.881135      0      0     1      7  27.0   \n",
      "639        3         0    1   5.000000      4      2     3      7  27.0   \n",
      "\n",
      "            body  lname  nameprefix  \n",
      "id                                   \n",
      "277   160.809917    755          20  \n",
      "562   160.809917    741          16  \n",
      "111   160.809917    257          16  \n",
      "930   160.809917    406          19  \n",
      "841   160.809917    303          16  \n",
      "585   293.000000    830          19  \n",
      "609   103.000000      7          19  \n",
      "540   160.809917    652          16  \n",
      "1075  160.809917    591          19  \n",
      "390   160.809917    198          19  \n",
      "921   160.809917    399          19  \n",
      "339   160.809917     66          13  \n",
      "155   160.809917    323          20  \n",
      "564   160.809917    747          16  \n",
      "694   160.809917    108          19  \n",
      "1028  160.809917    538          16  \n",
      "1184  160.809917    706          19  \n",
      "633   160.809917     22          19  \n",
      "907   160.809917    388          16  \n",
      "426    75.000000    306          19  \n",
      "1210  160.809917    739          19  \n",
      "257   160.809917    712          20  \n",
      "474   165.000000    418          19  \n",
      "439   160.809917    335          19  \n",
      "9      22.000000     30          19  \n",
      "948   160.809917    426          19  \n",
      "762   160.809917    199          13  \n",
      "802   160.809917    252          19  \n",
      "482   160.809917    435          16  \n",
      "893   160.809917    381          19  \n",
      "...          ...    ...         ...  \n",
      "408   160.809917    247          19  \n",
      "87    160.809917    190          19  \n",
      "810   160.809917    255          19  \n",
      "276   160.809917    755          19  \n",
      "751   160.809917    193          19  \n",
      "550   160.809917    666          20  \n",
      "231   160.809917    641          12  \n",
      "879   160.809917    367          19  \n",
      "896   160.809917    382          19  \n",
      "835   160.809917    299          19  \n",
      "752   160.809917    195          19  \n",
      "984   160.809917    474          16  \n",
      "163   160.809917    349          20  \n",
      "1063  160.809917    573          19  \n",
      "29    160.809917     83          19  \n",
      "200   292.000000    499          19  \n",
      "285    96.000000    772          19  \n",
      "1267  160.809917    811           9  \n",
      "783   160.809917    226          19  \n",
      "1074  160.809917    584          19  \n",
      "1087  160.809917    595          19  \n",
      "982   160.809917    471          19  \n",
      "677   160.809917     88          19  \n",
      "977   160.809917    465          19  \n",
      "35    160.809917     92          16  \n",
      "626   160.809917     21          16  \n",
      "640   160.809917     33          13  \n",
      "845   160.809917    305          20  \n",
      "1291  160.809917    845          19  \n",
      "639   160.809917     33          13  \n",
      "\n",
      "[654 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "def fill_missing_data(df_train,df_test):\n",
    "    features = ['age', 'body', 'boat']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    df_imputer = preprocessing.Imputer()\n",
    "    df_imputer.fit(df_combined[features])\n",
    "    df_train[features] = df_imputer.transform(df_train[features])\n",
    "    df_test[features] = df_imputer.transform(df_test[features])\n",
    "    return df_train, df_test\n",
    "\n",
    "train_data,test_data = fill_missing_data(train_data,test_data)\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniStep 4  - Almost There!\n",
    "\n",
    "Get X (FeatureVectors - Actual training data) and Y ( training labels) . Once we get them, we will also scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<type 'numpy.ndarray'>, <type 'numpy.ndarray'>)\n"
     ]
    }
   ],
   "source": [
    "def get_X_Y_pair(df):\n",
    "    features = df.columns.values\n",
    "    x_features = [f for f in features if f!='survived']\n",
    "    return df[x_features], df['survived']\n",
    "\n",
    "def scale_data(df_train, df_test):\n",
    "    df_combine = pd.concat([df_train, df_test])\n",
    "    features = df_train.columns.values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df_combine)\n",
    "    return scaler.transform(df_train), scaler.transform(df_test)\n",
    "\n",
    "x_train, y_train = get_X_Y_pair(train_data)\n",
    "x_test, y_test = get_X_Y_pair(test_data)\n",
    "\n",
    "#not pandas after this\n",
    "x_train, x_test = scale_data(x_train,x_test)\n",
    "print(type(x_train), type(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are done arranging the data. Time To run some sample classifiers and see how they work out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Feed the classifier\n",
    "\n",
    "\n",
    "### MiniStep 2.1 - Setting up a meta-classifier\n",
    "Again, using scikit-learn, we have a great advantage here. Scikit-learn's classifiers come with a beautiful interface\n",
    "\n",
    "```\n",
    "Let's assume our classifier instance is clf\n",
    "clf = ClassifierName(ClassifierParams=...) #Defaults are usually good enough in most cases\n",
    "clf.fit (traindata, trainlabels) # Training\n",
    "test_answers = clf.predict(testdata) # Testing\n",
    "\n",
    "```\n",
    "\n",
    "since it's so beautiful, lets create a meta function that would train on any training data, test on some given testing data, calculate the accuracy for titanic dataset and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
